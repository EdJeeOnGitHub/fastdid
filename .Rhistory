return(open_dataset(paths, schema = sch))
} else {
head <- open_dataset(paths, format = fileformat)
sch <- head$schema
sch <- fix_scheme(sch)
return(open_dataset(paths, schema = sch, format = fileformat, skip = ifelse(fileformat == "parquet", 0, 1)))
}
}
# Create the arrow dataset ----------------------------------------------------------------------
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(!!rlang::parse_expr(partition))
dt |> write_dataset(out_folder)
}
csv_to_parquet <- function(in_folder, out_folder, overwrite = FALSE, filenames = NULL){
#go through a whole folder and try to turn every file from csv
message("It is recommended to run parse_csv_for_arrow first. Otherwise arrow will fail frequently.")
files <- list.files(in_folder, pattern = paste(filenames, collapse = "|"), ignore.case = TRUE)
files <- files[str_ends(files, ".csv|.tsv")]
for(file in files){
in_path <- paste0(in_folder, "/", file)
filename <- str_split_1(file, "\\.")[1]
out_path <- paste0(out_folder, "/", filename, ".parquet")
fileformat <- str_split_1(file, "\\.")[2]
if(!fileformat %in% c("csv", "tsv")){warning(filename, ".", fileformat, "is not in a familiar format!")}
if(file.exists(out_path) & overwrite == FALSE){
message(paste(filename, "already exists."))
next
}
csv_to_parquet_file(in_path, out_path)
}
}
csv_to_parquet_file <- function(in_path, out_path){
#try both arrow reading and (slower) data.table reading
tryCatch({
dt <- open_dataset_fix_sch(in_path)
dt %>% write_parquet(out_path)
#if error message Error: x must be an object of class 'data.frame', 'RecordBatch', or 'Table', not 'FileSystemDataset'.
#pops, probably mean the arrow version is too old
#https://github.com/apache/arrow/pull/11971
message(paste(out_path, "wrote with arrow."))
},
error = function(e) {
message("Error message: ", e)
message("Arrow failed, try data.table")
tryCatch(
{
dt <- fread(in_path)
dt %>% write_parquet(out_path)
message(paste(out_path, "wrote with data.table"))
},
error = function(e) {
message("Error message: ", e)
message("All failed!")
}
)
}
)
}
# Query the parquet dataset ----------------------------------------------
collect_by_ym <- function(query, years = Sys.getenv("START_YEAR"):Sys.getenv("END_YEAR"), only_yearly = FALSE, add = "no", verbose = TRUE, rename_to_upper = TRUE){
dt <- data.table()
for(y in years){
for(m in 1:ifelse(only_yearly, 1, 12)){
assign("y", y, envir = parent.env(environment()))
assign("m", m, envir = parent.env(environment()))
new_dt <- eval(enexpr(query), envir = parent.env(environment())) %>% collect() |> as.data.table()
if(add == "time"){
new_dt$TIME <- y*12+m
} else if (add == "ym") {
new_dt$Y <- y
new_dt$M <- m
}
dt <- dt %>% rbind(new_dt)
if(verbose){message(y, " ", m, " done")}
}
}
return(dt)
}
#open the relevant arrow datasets with one command!
open_nhi <- function(filename, years = NULL, months = NULL,
parquet_path = Sys.getenv("ARROW_PATH"),
path_only = FALSE,
rename_to_upper = TRUE){
if(any(years > 1911)){stop("Please use ROC year.")}
if(any(months > 12)){stop("Please use valid month.")}
#construct the ym regex
if(is.null(months)){
ym_regex <- ifelse(!is.null(years), str_flatten(years, collapse = "|"), ".")
} else {
months <- ifelse(as.numeric(months) < 10, paste0(0,months), months)
if(is.null(years)){
ym_regex <- months |> paste0("\\.|_") |> str_flatten("|")
} else {
ym_dt <- CJ(y = years, m = months)
ym_dt[, ym := paste0(y,m)]
ym_regex <- str_flatten(ym_dt$ym, collapse = "|")
}
}
paths <- list.files(path = parquet_path, pattern = filename, full.names = TRUE, ignore.case = TRUE)
paths <- str_subset(paths, ym_regex)
if(length(paths) == 0){stop("Didn't find any file!")}
if(path_only){return(paths)}
dt <- open_dataset_fix_sch(paths)
if(rename_to_upper){dt <- dt |> rename_with(toupper)}
return(dt)
}
# Not maintained ------------------------------------
merge_nhi <- function(dt, merged_file, years = NULL, months = NULL, merge_var = NA, pre_filter = TRUE){
#bascially something that automatically get the matching columns
#save a little bit of time I guess
if(is.na(merge_var)){
if(merged_file %in% c("OPDTO", "IPDTO")){
merge_var <- c("FEE_YM", "APPL_TYPE", "HOSP_ID", "APPL_DATE", "CASE_TYPE", "SEQ_NO")
} else if(merged_file == "ENROL"){merge_var <- "ID"}
else {stop("No merge var with no default (default is provided for DTOs, ENROL.)")}
}
to_merge <- open_nhi(merged_file, years = years, months = months)
#need to filter the relevant ones out first, otherwise crash sometimes
if(pre_filter & merged_file == "OPDTE"){
#create the keys
eo_keys <- dt %>% mutate(eo_key = paste0(SEQ_NO, "_", APPL_DATE, "_", HOSP_ID)) %>%
distinct(eo_key) %>% collect() %>% unlist()
#merge with dto
to_merge <- to_merge %>%  mutate(eo_key = paste0(SEQ_NO, "_", APPL_DATE, "_", HOSP_ID)) %>%
filter(eo_key %in% eo_keys) #the filtering
}
merged <- left_join(dt, to_merge, by = merge_var)
return(merged)
}
run_til_success <- function(call, max_try = 10){
#takes a call and run it as a separate file until it returns 0
#need to include needed package/variables since it will be executed in a new session
call <- enquo(call)
call %>% deparse(backtick = TRUE) %>%  str_remove("~") %>% writeLines("code.r")
return_message <- 1
try <- 1
while(return_message != 0 & try < max_try){
message(try, " try.")
return_message <- system("Rscript code.r")
try <- try + 1
}
unlink("code.r")
return(return_message)
}
library(testthat)
source("~/GitHub/nhiHelper/arrow/arrow_helpers.R")
csv_folder <- "C:/Users/User/Documents/GitHub/nhiHelper/data/csv"
arrow_folder <- Sys.getenv("ARROW_PATH")
schema_path <- Sys.getenv("SCHEMA_PATH")
parsed_path <- Sys.getenv("PARSED_PATH")
message("clean all parquet file before starting")
unlink(list.files(arrow_folder, full.names = TRUE))
unlink(schema_path)
parse_csv_for_arrow(csv_folder)
schema <- fread(schema_path)
unlink(parsed_path)
parse_csv_for_arrow(csv_folder)
schema <- fread(schema_path)
csv_to_parquet_dataset
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "opdte", partition = "FEE_YM")
unlink(list.files(arrow_folder, full.names = TRUE))
?unlink(list.files(arrow_folder, full.names = TRUE))
?list.files
unlink(list.files(arrow_folder, full.names = TRUE, recursive = TRUE))
?unlink
unlink(list.files(arrow_folder, full.names = TRUE, recursive = TRUE), recursive = TRUE)
unlink(arrow_folder, recursive = TRUE)
?dir.create
dir.create(arrow_folder)
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(!!rlang::parse_expr(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "opdte", partition = "FEE_YM")
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM")
opdte <- open_dataset(paste0(arrow_path, "/OPDTE")) |> filter(FEE_YM == "201412") |> summarise(n = n()) |> collect()
opdte <- open_dataset(paste0(arrow_path, "/OPDTE")) |> filter(FEE_YM = "201412") |> summarise(n = n()) |> collect()
op <- open_dataset(paste0(arrow_path, "/OPDTE"))
head(op)
opdte <- open_dataset(paste0(arrow_path, "/OPDTE")) |> filter(FEE_YM == 201412) |> summarise(n = n()) |> collect()
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM, FUNC_TYPE")
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM,FUNC_TYPE")
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(!all_of(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = c("FEE_YM", "FUNC_TYPE"))
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM")
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(all_of(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(all_of(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM")
?parse_expr
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(!!rlang::parse_exprs(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = c("FEE_YM", "FUNC_TYPE"))
csv_to_parquet_dataset <- function(in_folder, out_folder, overwrite = FALSE, filename, partition){
paths <- list.files(path = in_folder, pattern = filename, ignore.case = TRUE, full.names = TRUE)
dt <- open_dataset_fix_sch(paths) |> group_by(!!rlang::parse_expr(partition))
dt |> write_dataset(paste0(out_folder, "/", filename))
}
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM")
open_nhi_dt <- function(filename, parquet_path = Sys.getenv("ARROW_PATH")){
return(open_dataset(paste0(parquet_path, "/", filename)))
}
op <- open_nhi_dt("OPDTE")
op |> summarize(n = n()) |> collect()
sum <- op |> summarize(n = n()) |> collect()
sum$n
test_that("test arrow full dataset",{
unlink(arrow_folder, recursive = TRUE)
dir.create(arrow_folder)
csv_to_parquet_dataset(csv_folder, arrow_path, filename = "OPDTE", partition = "FEE_YM")
op <- open_nhi_dt("OPDTE")
sum <- op |> summarize(n = n()) |> collect()
expect_equal(sum$n, 1667307)
})
text <- "| NUM | FUNC_TYPE | COUNT_MEAN | YEARLY_RATIO | QUARTERLY_RATIO | PAIR_COUNT |
|-----|-----------|------------|--------------|-----------------|------------|
|   1 |        2B |       7.06 |         0.62 |            0.33 |        381 |
|   2 |        AB |       3.94 |         0.34 |            0.16 |      11723 |
|   3 |        AE |       3.63 |         0.33 |            0.14 |       7492 |
|   4 |        2A |       3.19 |         0.40 |            0.09 |        385 |
|   5 |        13 |       2.91 |         0.31 |            0.07 |       5159 |
|   6 |        12 |       2.88 |         0.28 |            0.09 |       7085 |
|   7 |        AD |       2.87 |         0.39 |            0.01 |       1806 |
|   8 |        AG |       2.76 |         0.29 |            0.08 |       2500 |
|   9 |        07 |       2.72 |         0.30 |            0.06 |       1100 |
|  10 |        AF |       2.63 |         0.22 |            0.08 |        790 |
|  11 |        14 |       2.62 |         0.27 |            0.06 |      8420 |
|  12 |        00 |       2.42 |         0.27 |            0.04 |    324169 |
|  13 |        BB |       2.24 |         0.51 |            0.00 |       441 |
|  14 |        02 |       2.20 |         0.21 |            0.04 |    189814 |
|  15 |        04 |       2.20 |         0.25 |            0.03 |     36855 |
|  16 |        08 |       2.20 |         0.17 |            0.04 |     11668 |
|  17 |        60 |       2.16 |         0.22 |            0.03 |    198662 |
|  18 |        01 |       2.12 |         0.21 |            0.03 |    166693 |
|  19 |        05 |       1.98 |         0.18 |            0.03 |     27546 |
|  20 |        AC |       1.97 |         0.16 |            0.04 |      2575 |
|  21 |        10 |       1.94 |         0.18 |            0.02 |     25542 |
|  22 |        BA |       1.93 |         0.21 |            0.02 |      6776 |
|  23 |        AA |       1.81 |         0.22 |            0.01 |      1906 |
|  24 |        11 |       1.78 |         0.16 |            0.01 |     65444 |
|  25 |        BD |       1.76 |         0.14 |            0.02 |      1338 |
|  26 |        06 |       1.66 |         0.12 |            0.01 |     36492 |
|  27 |        09 |       1.65 |         0.14 |            0.01 |     64460 |
|  28 |        40 |       1.62 |         0.14 |            0.00 |     75909 |
|  29 |        03 |       1.49 |         0.10 |            0.01 |     73380 |
|  30 |        22 |       1.09 |         0.01 |            0.00 |      3556 |"
library(stringr)
text2 <- text |> str_trim()
text2
text2 <- text |> str_trim(side = "both")
9e9
?glm
?lm
?interaction
library(cem)
data(LL)
todrop <- c("treated","re78")
imbalance(LL$treated, LL, drop=todrop)
mat <- cem(treatment="treated", data=LL, drop="re78")
mat$strata
?feols
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = TRUE)
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = TRUE)
source("source/setup.R")
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = TRUE)
dt <- simdt$dt
source("source_raw/eventcode_IV.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
never_treat_action = "both")
event_panel <- event_panel %>% construct_event_variables(event_panel)
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE, mem.clean = FALSE)
})
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
source("source/setup.R")
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = TRUE)
dt <- simdt$dt
source("source_raw/eventcode_IV.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
never_treat_action = "both")
event_panel <- event_panel %>% construct_event_variables(event_panel)
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE)
})
source("source_raw/eventcode_IV.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
never_treat_action = "both")
event_panel <- event_panel %>% construct_event_variables(event_panel)
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE)
})
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = TRUE)
dt <- simdt$dt
# new event code ---------------------------------------------------------------------
source("source/setup.R")
source("source/preprocess.R")
source("source/estimation.R")
source("source/report.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y", "y2")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
balanced_panel = TRUE,
never_treat_action = "both")
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE, mem.clean = FALSE)
})
att_comp <- validate_att_est(simdt$att, event_est)
rm(list = ls())
gc()
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = FALSE)
source("source/setup.R")
source("source/preprocess.R")
source("source/estimation.R")
source("source/report.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
balanced_panel = TRUE,
never_treat_action = "both")
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE, mem.clean = FALSE)
})
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = FALSE)
dt <- simdt$dt
# new event code ---------------------------------------------------------------------
source("source/setup.R")
source("source/preprocess.R")
source("source/estimation.R")
source("source/report.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
balanced_panel = TRUE,
never_treat_action = "both")
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE, mem.clean = FALSE)
})
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = FALSE)
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = FALSE)
rm(list = ls())
gc()
library(profvis)
library(microbenchmark)
setwd("~/GitHub/EventStudyCode")
source("sim_did.R")
source("source/setup.R")
# simulation ---------------------------------------------------------------------
#test with did
simdt <- sim_did(100000, 10, cov = "int", hetero = "dynamic", balanced = FALSE, second_outcome = FALSE)
dt <- simdt$dt
# new event code ---------------------------------------------------------------------
source("source/preprocess.R")
source("source/estimation.R")
source("source/report.R")
profvis({
event_panel <- copy(dt) #copying so that the original does not change
min_time <- -Inf
max_time <- Inf
y_name <- c("y")
t_name <- "time"
unit_name <- "unit"
cohort_name <- "G"
balance_covariate <- "x"
event_panel <- event_panel %>% create_event_data(timevar = t_name, unitvar = unit_name,
cohortvar = cohort_name,
covariate_base_balance = balance_covariate,
balanced_panel = TRUE,
never_treat_action = "both")
event_est <- get_result_dynamic(event_panel, variable = y_name, trends = FALSE, mem.clean = FALSE)
})
att_comp <- validate_att_est(simdt$att, event_est)
